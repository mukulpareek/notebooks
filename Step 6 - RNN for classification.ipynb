{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing with an RNN  \n",
    "  \n",
    "In order to get the RNN to consume text data, we need two things:  \n",
    "  \n",
    "1. A list of all the texts, eg `texts = ['Today is a nice day', 'Yesterday was gorgeous',....]`  \n",
    "2. We need the labels in a list too, eg `labels = [1, 0, 1, 1,...]`.  If labels are text string categories, then use one-hot encoding to convert them into an array, with each row of the array corresponding to an observation.  \n",
    "  \n",
    "We first set up a tokenizer as follows:  \n",
    "  \n",
    "```python\n",
    "from keras.preprocessing.text import Tokenizer  \n",
    "from keras.preprocessing.sequence import pad_sequences  \n",
    "  \n",
    "tokenizer = Tokenizer(num_words = vocab_size) #Sets up a blank tokenizer  \n",
    "tokenizer.fit_on_texts(texts)   \n",
    "# fit_on_texts creates the vocabulary based on `texts`, based on word frequency. So if you give it something like, \"The cat sat on the mat.\" It will create a dictionary s.t. word_index[\"the\"] = 1; word_index[\"cat\"] = 2 it is word -> index dictionary so every word gets a unique integer value. 0 is reserved for padding. So lower integer means more frequent word (often the first few are stop words because they appear a lot).  \n",
    "  \n",
    "sequences = tokenizer.texts_to_sequences(texts)  \n",
    "# This step transforms each text in texts to a sequence of integers. So it basically takes each word in the text and replaces it with its corresponding integer value from the word_index dictionary.   \n",
    "  \n",
    "word_index = tokenizer.word_index # This is the dictionary of words and their indexes which one can see using  word_index.items()  \n",
    "  \n",
    "data = pad_sequences(sequences, maxlen = maxlen) # Here we make all texts equal in length, and padding is pre (can be changed   by padding='post')  \n",
    "  \n",
    "labels = np.asarray(labels) # We convert the labels into an array from its original list form.  \n",
    "\n",
    "```  \n",
    "  \n",
    "At this point all our input text data exists as perfectly sized tensors in the variable called `data`, and `labels`.  The `data` variable has references to the `word_index` which is essentially the dictionary for the task.  \n",
    "  \n",
    "Next, we need to create the embeddings_matrix based on Glove.  For this, we first load up Glove in a giant matrix, and then we look up each item in the `word_index` in the Glove matrix and create our pre-trained embeddings_matrix based on Glove.  In this matrix, we preserve the index order as in the `word_index`, so what is #3 in the word index is also the 3rd row in the embeddings_matrix.  The 0th row is all zeros, and only the first row onwards are used because in the `word_index` dictionary there is no entry for zero.  \n",
    "  \n",
    "Now we are good to go to feed this into our NN. The pretrained embeddings_matrix makes its way into the NN using the following commands:  \n",
    "  \n",
    "```python\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False\n",
    "```\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'summary_x', 'URL', 'keywords', 'summary_y', 'text',\n",
       "       'published_date', 'corona'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "df = joblib.load('final_df3.pkl')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = (np.random.randint(0,2,970))\n",
    "labels = df.corona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# imdb_dir = '\\\\Users\\\\user\\\\aclImdb'\n",
    "# train_dir = os.path.join(imdb_dir, 'train')\n",
    "# labels=[]\n",
    "# texts=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the text files\n",
    "# for label_type in ['neg','pos']:\n",
    "#     dir_name = os.path.join(train_dir, label_type)\n",
    "#     for fname in os.listdir(dir_name):\n",
    "#         if fname[-4:]== '.txt':\n",
    "#             f = open(os.path.join(dir_name, fname))\n",
    "#             #print(fname)\n",
    "#             texts.append(f.read())\n",
    "#             f.close()\n",
    "#             if label_type =='neg':\n",
    "#                 labels.append(0)\n",
    "#             else:\n",
    "#                 labels.append(1)\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the variable `texts` contains all the reviews in plaintext as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in texts is 6036 \n",
      " Its stats are:\n",
      "count    6036.000000\n",
      "mean      563.801359\n",
      "std       517.209699\n",
      "min         1.000000\n",
      "25%       265.000000\n",
      "50%       437.000000\n",
      "75%       762.000000\n",
      "max      7244.000000\n",
      "dtype: float64\n",
      "-----\n",
      "Number of labels count is 6036\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Number of items in texts is', len(texts), '\\n Its stats are:')\n",
    "print(pd.Series([len(texts[i].split(' ')) for i in range(len(texts))]).describe())\n",
    "pd.Series([len(texts[i].split(' ')) for i in range(len(texts))]).plot.hist()\n",
    "print('-----')\n",
    "print('Number of labels count is', len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 74822 unique tokens\n",
      "Shape of data tensor (6036, 5000)\n",
      "Shape of label tensor (6036,)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen=5000  # how many words to take from each text\n",
    "training_samples=int(len(texts) * 0.8)\n",
    "validation_samples = len(texts) - training_samples\n",
    "vocab_size=20000\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens' % len(word_index))\n",
    "data = pad_sequences(sequences, maxlen = maxlen)\n",
    "labels = np.asarray(labels)\n",
    "print('Shape of data tensor', data.shape)\n",
    "print('Shape of label tensor', labels.shape)\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples:training_samples+validation_samples]\n",
    "y_val = labels[training_samples:training_samples+validation_samples]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(79.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6036"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 words and corresponding vectors\n"
     ]
    }
   ],
   "source": [
    "glove_dir = '\\\\Users\\\\user\\\\glove.6B'\n",
    "\n",
    "embeddings_index = {}\n",
    "#f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "f=open('\\\\Users\\\\user\\\\glove.6B\\\\glove.6B.100d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype = 'float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s words and corresponding vectors' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_index.get('security'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_index.get('th13e'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the embedding matrix based on Glove\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < vocab_size:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the `embedding_matrix` has one row per word in the vocabulary.  Each row has the vector for that word, picked from glove.  Because it is an np.array, it has no row or column names. The order of the words in the rows is the same as the order of words in the dict word_index.  \n",
    "  \n",
    "We will feed this embedding matrix as weights to the embedding layer.  \n",
    "  \n",
    "## Build the model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, LSTM, SimpleRNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         2000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,017,057\n",
      "Trainable params: 2,017,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim)) # Note that vocab_size=10000 (vocab size), embedding_dim = 100 (100 dense vector for each word from Glove), maxlen=100 (using only first 100 words of each review)\n",
    "model.add(LSTM(32))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3862 samples, validate on 966 samples\n",
      "Epoch 1/15\n",
      "3862/3862 [==============================] - 335s 87ms/step - loss: 0.5318 - acc: 0.7740 - val_loss: 0.5191 - val_acc: 0.7961\n",
      "Epoch 2/15\n",
      "3862/3862 [==============================] - 328s 85ms/step - loss: 0.5180 - acc: 0.7869 - val_loss: 0.5153 - val_acc: 0.7961\n",
      "Epoch 3/15\n",
      "3862/3862 [==============================] - 316s 82ms/step - loss: 0.5147 - acc: 0.7869 - val_loss: 0.5237 - val_acc: 0.7961\n",
      "Epoch 4/15\n",
      "3862/3862 [==============================] - 283s 73ms/step - loss: 0.5137 - acc: 0.7869 - val_loss: 0.5163 - val_acc: 0.7961\n",
      "Epoch 5/15\n",
      "3862/3862 [==============================] - 279s 72ms/step - loss: 0.5106 - acc: 0.7869 - val_loss: 0.5150 - val_acc: 0.7961\n",
      "Epoch 6/15\n",
      "3862/3862 [==============================] - 274s 71ms/step - loss: 0.5090 - acc: 0.7872 - val_loss: 0.5226 - val_acc: 0.7961\n",
      "Epoch 7/15\n",
      "3862/3862 [==============================] - 278s 72ms/step - loss: 0.5068 - acc: 0.7872 - val_loss: 0.5215 - val_acc: 0.7961\n",
      "Epoch 8/15\n",
      "3862/3862 [==============================] - 277s 72ms/step - loss: 0.5039 - acc: 0.7872 - val_loss: 0.5264 - val_acc: 0.7950\n",
      "Epoch 9/15\n",
      "3862/3862 [==============================] - 274s 71ms/step - loss: 0.5007 - acc: 0.7882 - val_loss: 0.5219 - val_acc: 0.7950\n",
      "Epoch 10/15\n",
      "3862/3862 [==============================] - 286s 74ms/step - loss: 0.4991 - acc: 0.7879 - val_loss: 0.5298 - val_acc: 0.7930\n",
      "Epoch 11/15\n",
      "3862/3862 [==============================] - 283s 73ms/step - loss: 0.4957 - acc: 0.7895 - val_loss: 0.5232 - val_acc: 0.7950\n",
      "Epoch 12/15\n",
      "3862/3862 [==============================] - 279s 72ms/step - loss: 0.4919 - acc: 0.7892 - val_loss: 0.5260 - val_acc: 0.7950\n",
      "Epoch 13/15\n",
      "3862/3862 [==============================] - 275s 71ms/step - loss: 0.4914 - acc: 0.7897 - val_loss: 0.5276 - val_acc: 0.7950\n",
      "Epoch 14/15\n",
      "3862/3862 [==============================] - 288s 75ms/step - loss: 0.4853 - acc: 0.7905 - val_loss: 0.5378 - val_acc: 0.7950\n",
      "Epoch 15/15\n",
      "3862/3862 [==============================] - 281s 73ms/step - loss: 0.4816 - acc: 0.7910 - val_loss: 0.5704 - val_acc: 0.7650\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train, epochs=15, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
