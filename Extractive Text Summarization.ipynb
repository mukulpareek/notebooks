{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACTIVE TEXT SUMMARIZATION\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    " \n",
    "def read_article(file_name):\n",
    "    file = open(file=file_name ,mode = \"r\", encoding=\"utf8\" )\n",
    "    filedata = file.readlines()\n",
    "    article = filedata[0].split(\". \")\n",
    "    sentences = []\n",
    "\n",
    "    for sentence in article:\n",
    "        print(sentence)\n",
    "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "    sentences.pop() \n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    " \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    " \n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    # Create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "def generate_summary(file_name, top_n=5):\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "\n",
    "    # Step 1 - Read text anc split it\n",
    "    sentences =  read_article(file_name)\n",
    "\n",
    "    # Step 2 - Generate Similary Martix across sentences\n",
    "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
    "\n",
    "    # Step 3 - Rank sentences in similarity martix\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "\n",
    "    # Step 4 - Sort the rank and pick top sentences\n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
    "\n",
    "    for i in range(top_n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "\n",
    "    # Step 5 - Offcourse, output the summarize texr\n",
    "    print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n",
    "\n",
    "# let's begin\n",
    "# generate_summary( \"msft.txt\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May 2014 Code is complex, and in the coming days is going to get more complex\n",
      "Over many generations of programming languages, we have increasingly abstracted ourselves away from the bits and bytes that run as machine code on the processor\n",
      "That has allowed us to create increasingly complex software to a point where if you can dream it, you can code it\n",
      "Our imagination is the only constraint on what software can do, which incidentally is also why software is eating jobs\n",
      "Source code that humans write today is multiple layers of compilation and interpretation away from the zeroes-and-ones that ultimately runs on the microprocessor\n",
      "Though the machine level code produced through these layers is less than perfectly optimized, that does not present a problem as both storage and computing are no longer constraints\n",
      "Yet one problem it produces is that humans barely have any ability to understand the actual code that gets executed\n",
      "Though there are decompilers, their ability to make apples out of applesauce is limited\n",
      "The implication of that is with just about everything around us running code – the greeting card with a microcontroller that plays a tune and blinks LEDs, your car, your stereo, your television, your security system, your thermostat – we have absolutely no ability to judge the quality of the code, if we can get to it at all\n",
      "Given the unknown provenance of most of this code, that is assuming it wasn't designed to attack you in the first place, or has been modified to do so\n",
      "This problem is going to get more difficult\n",
      "Mass production and miniaturization means there will be more microcontrollers and processors, and with radios built in with a view to network\n",
      "Add to the mix flexible touch displays and incredibly inexpensive yet powerful sensors, the implications for security and privacy are monumental\n",
      "In order to stay in control of our information and destinies, we will need to fundamentally rethink security along a dimension that looks at the problem differently from applying patches and firmware updates\n",
      "What that answer is, if there is one, only time will tell.\n",
      "\n",
      "Indexes of top ranked_sentence order are  [(0.12592653412962512, ['Yet', 'one', 'problem', 'it', 'produces', 'is', 'that', 'humans', 'barely', 'have', 'any', 'ability', 'to', 'understand', 'the', 'actual', 'code', 'that', 'gets', 'executed']), (0.11497487520598768, ['May', '2014', 'Code', 'is', 'complex,', 'and', 'in', 'the', 'coming', 'days', 'is', 'going', 'to', 'get', 'more', 'complex']), (0.11316132337055175, ['That', 'has', 'allowed', 'us', 'to', 'create', 'increasingly', 'complex', 'software', 'to', 'a', 'point', 'where', 'if', 'you', 'can', 'dream', 'it,', 'you', 'can', 'code', 'it']), (0.10747515422812445, ['Though', 'the', 'machine', 'level', 'code', 'produced', 'through', 'these', 'layers', 'is', 'less', 'than', 'perfectly', 'optimized,', 'that', 'does', 'not', 'present', 'a', 'problem', 'as', 'both', 'storage', 'and', 'computing', 'are', 'no', 'longer', 'constraints']), (0.10551412836490533, ['The', 'implication', 'of', 'that', 'is', 'with', 'just', 'about', 'everything', 'around', 'us', 'running', 'code', '–', 'the', 'greeting', 'card', 'with', 'a', 'microcontroller', 'that', 'plays', 'a', 'tune', 'and', 'blinks', 'LEDs,', 'your', 'car,', 'your', 'stereo,', 'your', 'television,', 'your', 'security', 'system,', 'your', 'thermostat', '–', 'we', 'have', 'absolutely', 'no', 'ability', 'to', 'judge', 'the', 'quality', 'of', 'the', 'code,', 'if', 'we', 'can', 'get', 'to', 'it', 'at', 'all']), (0.09424912230352725, ['This', 'problem', 'is', 'going', 'to', 'get', 'more', 'difficult']), (0.08022984428405644, ['Over', 'many', 'generations', 'of', 'programming', 'languages,', 'we', 'have', 'increasingly', 'abstracted', 'ourselves', 'away', 'from', 'the', 'bits', 'and', 'bytes', 'that', 'run', 'as', 'machine', 'code', 'on', 'the', 'processor']), (0.07734016416783873, ['Source', 'code', 'that', 'humans', 'write', 'today', 'is', 'multiple', 'layers', 'of', 'compilation', 'and', 'interpretation', 'away', 'from', 'the', 'zeroes-and-ones', 'that', 'ultimately', 'runs', 'on', 'the', 'microprocessor']), (0.04955075146669677, ['In', 'order', 'to', 'stay', 'in', 'control', 'of', 'our', 'information', 'and', 'destinies,', 'we', 'will', 'need', 'to', 'fundamentally', 'rethink', 'security', 'along', 'a', 'dimension', 'that', 'looks', 'at', 'the', 'problem', 'differently', 'from', 'applying', 'patches', 'and', 'firmware', 'updates']), (0.039548531063635005, ['Though', 'there', 'are', 'decompilers,', 'their', 'ability', 'to', 'make', 'apples', 'out', 'of', 'applesauce', 'is', 'limited']), (0.032058292611149314, ['Add', 'to', 'the', 'mix', 'flexible', 'touch', 'displays', 'and', 'incredibly', 'inexpensive', 'yet', 'powerful', 'sensors,', 'the', 'implications', 'for', 'security', 'and', 'privacy', 'are', 'monumental']), (0.03067706256247025, ['Our', 'imagination', 'is', 'the', 'only', 'constraint', 'on', 'what', 'software', 'can', 'do,', 'which', 'incidentally', 'is', 'also', 'why', 'software', 'is', 'eating', 'jobs']), (0.017887372134968077, ['Given', 'the', 'unknown', 'provenance', 'of', 'most', 'of', 'this', 'code,', 'that', 'is', 'assuming', 'it', \"wasn't\", 'designed', 'to', 'attack', 'you', 'in', 'the', 'first', 'place,', 'or', 'has', 'been', 'modified', 'to', 'do', 'so']), (0.011406844106463889, ['Mass', 'production', 'and', 'miniaturization', 'means', 'there', 'will', 'be', 'more', 'microcontrollers', 'and', 'processors,', 'and', 'with', 'radios', 'built', 'in', 'with', 'a', 'view', 'to', 'network'])]\n",
      "Summarize Text: \n",
      " Yet one problem it produces is that humans barely have any ability to understand the actual code that gets executed. May 2014 Code is complex, and in the coming days is going to get more complex\n"
     ]
    }
   ],
   "source": [
    "generate_summary( \"op_ed.txt\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
